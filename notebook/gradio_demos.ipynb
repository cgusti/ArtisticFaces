{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Yji3ZSsUO8x"
      },
      "outputs": [],
      "source": [
        "pip install gradio\n",
        "pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import numpy as np \n",
        "import tensorflow as tf\n",
        "import requests"
      ],
      "metadata": {
        "id": "0GA_s-pqYQor"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Hello, World"
      ],
      "metadata": {
        "id": "j-IzKj-aUm-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def greet(name):\n",
        "    return \"Hello \" + name + \"!\"\n",
        "\n",
        "demo = gr.Interface(fn=greet, inputs=\"text\", outputs=\"text\")\n",
        "\n",
        "demo.launch()   "
      ],
      "metadata": {
        "id": "FcpFhOl6UldD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Sepia filter (uploaded Image)"
      ],
      "metadata": {
        "id": "9Smmu2hPU504"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sepia(input_img):\n",
        "    sepia_filter = np.array([\n",
        "        [0.393, 0.769, 0.189], \n",
        "        [0.349, 0.686, 0.168], \n",
        "        [0.272, 0.534, 0.131]\n",
        "    ])\n",
        "    sepia_img = input_img.dot(sepia_filter.T)\n",
        "    sepia_img /= sepia_img.max()\n",
        "    return sepia_img\n",
        "\n",
        "demo = gr.Interface(sepia, gr.Image(shape=(200, 200)), \"image\")\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "gq3pKKKdUTyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Webcam"
      ],
      "metadata": {
        "id": "yXp_BIWqV2t9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def snap(image, video):\n",
        "    return [image, video]\n",
        "\n",
        "\n",
        "demo = gr.Interface(\n",
        "    snap,\n",
        "    [gr.Image(source=\"webcam\", tool=None), gr.Video(source=\"webcam\")],\n",
        "    [\"image\", \"video\"],\n",
        ")\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "ygif4OAiV8tZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Image Classification"
      ],
      "metadata": {
        "id": "UM0wIzipYGbr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inception_net = tf.keras.applications.MobileNetV2()\n",
        "\n",
        "# Download human-readable labels for ImageNet.\n",
        "response = requests.get(\"https://git.io/JJkYN\")\n",
        "labels = response.text.split(\"\\n\")\n",
        "\n",
        "def classify_image(inp):\n",
        "  inp = inp.reshape((-1, 224, 224, 3))\n",
        "  inp = tf.keras.applications.mobilenet_v2.preprocess_input(inp)\n",
        "  prediction = inception_net.predict(inp).flatten()\n",
        "  confidences = {labels[i]: float(prediction[i]) for i in range(1000)}\n",
        "  return confidences\n",
        "\n",
        "gr.Interface(fn=classify_image, \n",
        "             inputs=gr.Image(shape=(224, 224)),\n",
        "             outputs=gr.Label(num_top_classes=3)).launch()"
      ],
      "metadata": {
        "id": "QTHqP5eWYGF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Components"
      ],
      "metadata": {
        "id": "5ow1EdpUcMHs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence_builder(quantity, animal, countries, place, activity_list, morning):\n",
        "    return f\"\"\"The {quantity} {animal}s from {\" and \".join(countries)} went to the {place} where they {\" and \".join(activity_list)} until the {\"morning\" if morning else \"night\"}\"\"\"\n",
        "\n",
        "\n",
        "demo = gr.Interface(\n",
        "    sentence_builder,\n",
        "    [\n",
        "        gr.Slider(2, 20, value=4, label=\"Count\", info=\"Choose betwen 2 and 20\"),\n",
        "        gr.Dropdown(\n",
        "            [\"cat\", \"dog\", \"bird\"], label=\"Animal\", info=\"Will add more animals later!\"\n",
        "        ),\n",
        "        gr.CheckboxGroup([\"USA\", \"Japan\", \"Pakistan\"], label=\"Countries\", info=\"Where are they from?\"),\n",
        "        gr.Radio([\"park\", \"zoo\", \"road\"], label=\"Location\", info=\"Where did they go?\"),\n",
        "        gr.Dropdown(\n",
        "            [\"ran\", \"swam\", \"ate\", \"slept\"], value=[\"swam\", \"slept\"], multiselect=True, label=\"Activity\", info=\"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed auctor, nisl eget ultricies aliquam, nunc nisl aliquet nunc, eget aliquam nisl nunc vel nisl.\"\n",
        "        ),\n",
        "        gr.Checkbox(label=\"Morning\", info=\"Did they do it in the morning?\"),\n",
        "    ],\n",
        "    \"text\",\n",
        "    examples=[\n",
        "        [2, \"cat\", \"park\", [\"ran\", \"swam\"], True],\n",
        "        [4, \"dog\", \"zoo\", [\"ate\", \"swam\"], False],\n",
        "        [10, \"bird\", \"road\", [\"ran\"], False],\n",
        "        [8, \"cat\", \"zoo\", [\"ate\"], True],\n",
        "    ],\n",
        ")\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "WgPAIy22cPDK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}